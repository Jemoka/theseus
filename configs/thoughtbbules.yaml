architecture:
  rope: true
  n_layers: 32
  n_embd: 2048
  block_size: 512
  dropout: 0.0
  vocab_size: 100288
  max_block_size: 1024
  fork:
  - 3
  - 6
  - 9
  bias: true
  n_head: 16
  use_fork_channel: true
  vram_calib_factor: 1.0
eval:
  evaluations: []
optimization:
  weight_decay: 0.1
  beta1: 0.9
  beta2: 0.95
  lr: 0.0003
training:
  batch_size: 512
  per_device_batch_size: 8
  tokens: 40000000000
  warmup_pct: 0.01
  decay_pct: 0.1
  validation: true
  evaluate: true
  dataset:
  - name: fineweb
    rate: 1.0
    style: PMD
    suffix: ''
  validation_steps: 2048
logging:
  report_interval: 32
  checkpoint_interval: 16384
  validation_interval: 2048
  wandb: true
job: thoughtbubbles/train/pretrain
request:
  chip: h200
  min_chips: 2
