"""
Theseus remote bootstrap - generated by dispatch()
"""
# mypy: ignore-errors

import json
import os
import signal
import sys
import threading
import time
from datetime import datetime
from pathlib import Path

from loguru import logger
from omegaconf import OmegaConf
from theseus.config import configuration
from theseus.registry import JOBS
from theseus.job import RestoreableJob
from theseus.base.job import ExecutionSpec
from theseus.base.hardware import HardwareResult, Cluster, ClusterMachine
from theseus.base.chip import SUPPORTED_CHIPS
from theseus.base.topology import Topology

# === EMBEDDED DATA (filled by dispatch.py) ===
CONFIG_YAML = """__CONFIG_YAML__"""
HARDWARE_JSON = """__HARDWARE_JSON__"""
JOB_NAME = "__JOB_NAME__"
PROJECT = "__PROJECT__"
GROUP = "__GROUP__"

BATCH_SIZE_OVERRIDE_ENV = "THESEUS_DISPATCH_BATCH_SIZE"
DISABLE_WANDB_ENV = "THESEUS_DISPATCH_DISABLE_WANDB"
RUN_ID_OVERRIDE_ENV = "THESEUS_DISPATCH_RUN_ID"
START_TIME_OVERRIDE_ENV = "THESEUS_DISPATCH_START_TIME"
ROOT_OVERRIDE_ENV = "THESEUS_DISPATCH_ROOT_OVERRIDE"
WORK_OVERRIDE_ENV = "THESEUS_DISPATCH_WORK_OVERRIDE"
LOG_OVERRIDE_ENV = "THESEUS_DISPATCH_LOG_OVERRIDE"


def setup_logging(verbose: bool = False, log_file: Path | None = None) -> None:
    """Configure loguru with appropriate log level."""
    logger.remove()

    log_format = (
        "<cyan>{time:YYYY-MM-DD HH:mm:ss}</cyan> |"
        "<level>{level: ^8}</level>| "
        "<magenta>({name}:{line})</magenta> <level>{message}</level>"
    )

    # Console handler
    logger.add(
        sys.stderr,
        format=log_format,
        level="DEBUG" if verbose else "INFO",
        colorize=True,
        enqueue=True,
        filter=lambda x: x["extra"].get("task", "") != "plot",
    )

    # File handler with colors preserved
    if log_file:
        log_file.parent.mkdir(parents=True, exist_ok=True)
        logger.add(
            str(log_file),
            format=log_format,
            level="DEBUG" if verbose else "INFO",
            colorize=True,  # Keep ANSI colors in file for streaming
            enqueue=True,
            filter=lambda x: x["extra"].get("task", "") != "plot",
        )


def _reconstruct_hardware(data: dict) -> HardwareResult:
    """Reconstruct HardwareResult from serialized JSON."""
    chip = SUPPORTED_CHIPS.get(data["chip"]) if data["chip"] else None
    root_override = os.environ.get(ROOT_OVERRIDE_ENV, "").strip() or None
    work_override = os.environ.get(WORK_OVERRIDE_ENV, "").strip() or None
    log_override = os.environ.get(LOG_OVERRIDE_ENV, "").strip() or None
    hosts = []
    for h in data["hosts"]:
        cluster_data = h["cluster"]
        cluster = Cluster(
            name=cluster_data["name"],
            root=root_override or cluster_data["root"],
            work=work_override or cluster_data["work"],
            log=log_override or cluster_data.get("log"),
        )
        resources = {
            SUPPORTED_CHIPS[k]: v
            for k, v in h["resources"].items()
            if k in SUPPORTED_CHIPS
        }
        hosts.append(
            ClusterMachine(name=h["name"], cluster=cluster, resources=resources)
        )
    return HardwareResult(chip=chip, hosts=hosts, total_chips=data["total_chips"])


def _get_status_dir(cluster: Cluster) -> Path:
    """Get status directory from cluster."""
    return cluster.status_dir


def _generate_run_id() -> str:
    """Generate unique run ID using timestamp and SLURM job ID if available."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    slurm_job_id = os.environ.get("SLURM_JOB_ID")
    if slurm_job_id:
        return f"{timestamp}_{slurm_job_id}"
    return timestamp


def _env_flag(name: str) -> bool:
    value = os.environ.get(name)
    if value is None:
        return False
    return value.strip().lower() not in {"", "0", "false", "no", "off"}


def _apply_runtime_config_overrides(cfg: OmegaConf) -> None:
    """Apply runtime config overrides provided by bootstrap.sh."""
    batch_size_override = os.environ.get(BATCH_SIZE_OVERRIDE_ENV)
    if batch_size_override is not None:
        try:
            batch_size = int(batch_size_override)
        except ValueError as exc:
            raise ValueError(
                f"{BATCH_SIZE_OVERRIDE_ENV} must be an integer, got: {batch_size_override}"
            ) from exc

        if (
            OmegaConf.select(cfg, "training.per_device_batch_size", default=None)
            is None
        ):
            print(
                "[bootstrap] WARNING:"
                " training.per_device_batch_size not found; skipping batch override"
            )
        else:
            OmegaConf.update(cfg, "training.per_device_batch_size", batch_size)
            print(
                f"[bootstrap] overriding training.per_device_batch_size to {batch_size}"
            )

    if _env_flag(DISABLE_WANDB_ENV):
        if OmegaConf.select(cfg, "logging.wandb", default=None) is not None:
            OmegaConf.update(cfg, "logging.wandb", False)
            print("[bootstrap] overriding logging.wandb to false for batch-size search")


def _write_metadata(
    metadata_file: Path,
    spec: ExecutionSpec,
    cfg: OmegaConf,
    run_id: str,
    status: str = "running",
    start_time: str | None = None,
) -> None:
    """Write job metadata to JSON file."""
    metadata = {
        "name": spec.name,
        "project": spec.project,
        "group": spec.group,
        "job_key": cfg.job,
        "run_id": run_id,
        "start_time": start_time or datetime.now().isoformat(),
        "last_heartbeat": datetime.now().isoformat(),
        "status": status,
        "slurm_job_id": os.environ.get("SLURM_JOB_ID"),
        "hardware": {
            "chip": spec.hardware.chip.name if spec.hardware.chip else None,
            "total_chips": spec.hardware.total_chips,
            "hosts": [h.name for h in spec.hardware.hosts],
        },
        "config": OmegaConf.to_container(cfg, resolve=True),
    }

    metadata_file.parent.mkdir(parents=True, exist_ok=True)
    with open(metadata_file, "w") as f:
        json.dump(metadata, f, indent=2)


def _setup_preemption_handler(
    metadata_file: Path,
    spec: ExecutionSpec,
    cfg: OmegaConf,
    run_id: str,
    start_time: str,
    heartbeat_updater=None,
) -> None:
    """Register signal handlers to catch SLURM preemption."""

    def handler(signum, frame):
        sig_name = signal.Signals(signum).name
        logger.warning(f"BOOTSTRAP | received {sig_name}, marking as preempted")
        if heartbeat_updater:
            heartbeat_updater.stop()
        _write_metadata(
            metadata_file, spec, cfg, run_id, status="preempted", start_time=start_time
        )
        sys.exit(128 + signum)

    signal.signal(signal.SIGTERM, handler)
    signal.signal(signal.SIGINT, handler)


class HeartbeatUpdater:
    """Background thread that periodically updates job heartbeat."""

    def __init__(
        self,
        metadata_file: Path,
        spec: ExecutionSpec,
        cfg: OmegaConf,
        run_id: str,
        start_time: str,
        interval: int = 30,
    ):
        self.metadata_file = metadata_file
        self.spec = spec
        self.cfg = cfg
        self.run_id = run_id
        self.start_time = start_time
        self.interval = interval
        self.stop_event = threading.Event()
        self.thread = None

    def start(self):
        """Start the heartbeat thread."""
        self.thread = threading.Thread(target=self._run, daemon=True)
        self.thread.start()
        logger.debug(f"HEARTBEAT | started with interval={self.interval}s")

    def stop(self):
        """Stop the heartbeat thread."""
        self.stop_event.set()
        if self.thread:
            self.thread.join(timeout=2)
        logger.debug("HEARTBEAT | stopped")

    def _run(self):
        """Run the heartbeat update loop."""
        while not self.stop_event.is_set():
            # Wait for the interval, but check stop_event more frequently
            for _ in range(self.interval):
                if self.stop_event.is_set():
                    return
                time.sleep(1)

            # Update heartbeat
            try:
                _write_metadata(
                    self.metadata_file,
                    self.spec,
                    self.cfg,
                    self.run_id,
                    status="running",
                    start_time=self.start_time,
                )
                logger.debug(f"HEARTBEAT | updated at {datetime.now().isoformat()}")
            except Exception as e:
                logger.warning(f"HEARTBEAT | failed to update: {e}")


def main():
    cfg = OmegaConf.create(CONFIG_YAML)
    _apply_runtime_config_overrides(cfg)
    hardware = _reconstruct_hardware(json.loads(HARDWARE_JSON))

    topology = Topology.new(hardware.chip) if hardware.chip else None
    spec = ExecutionSpec(
        name=JOB_NAME,
        project=PROJECT or None,
        group=GROUP or None,
        hardware=hardware,
        topology=topology,
        distributed=len(hardware.hosts) > 1,
    )

    # Get cluster and setup status directory
    cluster = hardware.hosts[0].cluster
    status_dir = _get_status_dir(cluster)

    # Generate unique run ID and capture start time
    run_id = os.environ.get(RUN_ID_OVERRIDE_ENV, "").strip() or _generate_run_id()
    start_time = (
        os.environ.get(START_TIME_OVERRIDE_ENV, "").strip()
        or datetime.now().isoformat()
    )

    # Create run-specific directory structure: status/{project}/{group}/{name}/{run_id}/
    project = spec.project or "general"
    group = spec.group or "default"
    run_dir = status_dir / project / group / spec.name / run_id
    run_dir.mkdir(parents=True, exist_ok=True)

    # Setup logging with file output
    log_file = run_dir / "output.log"
    metadata_file = run_dir / "metadata.json"
    setup_logging(log_file=log_file)

    logger.info(f"BOOTSTRAP | run_id={run_id}, log={log_file}")

    # Write initial metadata
    _write_metadata(
        metadata_file, spec, cfg, run_id, status="running", start_time=start_time
    )
    logger.info(f"METADATA | written to {metadata_file}")

    # Create heartbeat updater BEFORE importing JAX (which happens when job class is instantiated)
    heartbeat_updater = HeartbeatUpdater(
        metadata_file, spec, cfg, run_id, start_time, interval=30
    )

    # Register preemption handler for SLURM signals (with reference to heartbeat updater)
    _setup_preemption_handler(
        metadata_file, spec, cfg, run_id, start_time, heartbeat_updater
    )

    # Start heartbeat updater
    heartbeat_updater.start()

    job_key = cfg.job
    if job_key not in JOBS:
        heartbeat_updater.stop()
        _write_metadata(
            metadata_file, spec, cfg, run_id, status="failed", start_time=start_time
        )
        raise RuntimeError(
            f"Job '{job_key}' not in registry. Available: {list(JOBS.keys())}"
        )

    job_cls = JOBS[job_key]

    try:
        # Check for existing checkpoint if job is restorable (idempotent dispatch)
        if issubclass(job_cls, RestoreableJob):
            latest = RestoreableJob.latest(spec)
            if latest:
                logger.info(f"DISPATCH | restoring from checkpoint: {latest}")
                job, cfg = RestoreableJob.from_checkpoint(latest, spec)
                with configuration(cfg):
                    job()
                heartbeat_updater.stop()
                _write_metadata(
                    metadata_file,
                    spec,
                    cfg,
                    run_id,
                    status="completed",
                    start_time=start_time,
                )
                return

        # No checkpoint found, start fresh
        logger.info(f"DISPATCH | starting new job: {job_key}")
        with configuration(cfg):
            job = job_cls(spec)
            job()

        heartbeat_updater.stop()
        _write_metadata(
            metadata_file, spec, cfg, run_id, status="completed", start_time=start_time
        )
        logger.info("BOOTSTRAP | job completed successfully")

    except Exception as e:
        logger.exception(f"BOOTSTRAP | job failed with exception: {e}")
        heartbeat_updater.stop()
        _write_metadata(
            metadata_file, spec, cfg, run_id, status="failed", start_time=start_time
        )
        raise


if __name__ == "__main__":
    main()
