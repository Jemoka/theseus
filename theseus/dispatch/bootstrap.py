"""
Theseus remote bootstrap - generated by dispatch()
"""
# mypy: ignore-errors

import json
import os
import sys
from datetime import datetime
from pathlib import Path
from loguru import logger
from omegaconf import OmegaConf
from theseus.config import configuration
from theseus.registry import JOBS
from theseus.job import RestoreableJob
from theseus.base.job import ExecutionSpec
from theseus.base.hardware import HardwareResult, Cluster, ClusterMachine
from theseus.base.chip import SUPPORTED_CHIPS
from theseus.base.topology import Topology

# === EMBEDDED DATA (filled by dispatch.py) ===
CONFIG_YAML = """__CONFIG_YAML__"""
HARDWARE_JSON = """__HARDWARE_JSON__"""
JOB_NAME = "__JOB_NAME__"
PROJECT = "__PROJECT__"
GROUP = "__GROUP__"


def setup_logging(verbose: bool = False, log_file: Path | None = None) -> None:
    """Configure loguru with appropriate log level."""
    logger.remove()

    log_format = (
        "<cyan>{time:YYYY-MM-DD HH:mm:ss}</cyan> |"
        "<level>{level: ^8}</level>| "
        "<magenta>({name}:{line})</magenta> <level>{message}</level>"
    )

    # Console handler
    logger.add(
        sys.stderr,
        format=log_format,
        level="DEBUG" if verbose else "INFO",
        colorize=True,
        enqueue=True,
        filter=lambda x: x["extra"].get("task", "") != "plot",
    )

    # File handler with colors preserved
    if log_file:
        log_file.parent.mkdir(parents=True, exist_ok=True)
        logger.add(
            str(log_file),
            format=log_format,
            level="DEBUG" if verbose else "INFO",
            colorize=True,  # Keep ANSI colors in file for streaming
            enqueue=True,
            filter=lambda x: x["extra"].get("task", "") != "plot",
        )


def _reconstruct_hardware(data: dict) -> HardwareResult:
    """Reconstruct HardwareResult from serialized JSON."""
    chip = SUPPORTED_CHIPS.get(data["chip"]) if data["chip"] else None
    hosts = []
    for h in data["hosts"]:
        cluster = Cluster(
            name=h["cluster"]["name"],
            root=h["cluster"]["root"],
            work=h["cluster"]["work"],
        )
        resources = {
            SUPPORTED_CHIPS[k]: v
            for k, v in h["resources"].items()
            if k in SUPPORTED_CHIPS
        }
        hosts.append(
            ClusterMachine(name=h["name"], cluster=cluster, resources=resources)
        )
    return HardwareResult(chip=chip, hosts=hosts, total_chips=data["total_chips"])


def _get_status_dir(cluster: Cluster) -> Path:
    """Get status directory from cluster."""
    return cluster.status_dir


def _generate_run_id() -> str:
    """Generate unique run ID using timestamp and SLURM job ID if available."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    slurm_job_id = os.environ.get("SLURM_JOB_ID")
    if slurm_job_id:
        return f"{timestamp}_{slurm_job_id}"
    return timestamp


def _write_metadata(
    metadata_file: Path,
    spec: ExecutionSpec,
    cfg: OmegaConf,
    run_id: str,
    status: str = "running",
) -> None:
    """Write job metadata to JSON file."""
    metadata = {
        "name": spec.name,
        "project": spec.project,
        "group": spec.group,
        "job_key": cfg.job,
        "run_id": run_id,
        "start_time": datetime.now().isoformat(),
        "status": status,
        "slurm_job_id": os.environ.get("SLURM_JOB_ID"),
        "hardware": {
            "chip": spec.hardware.chip.name if spec.hardware.chip else None,
            "total_chips": spec.hardware.total_chips,
            "hosts": [h.name for h in spec.hardware.hosts],
        },
    }

    metadata_file.parent.mkdir(parents=True, exist_ok=True)
    with open(metadata_file, "w") as f:
        json.dump(metadata, f, indent=2)


def main():
    cfg = OmegaConf.create(CONFIG_YAML)
    hardware = _reconstruct_hardware(json.loads(HARDWARE_JSON))

    topology = Topology.new(hardware.chip) if hardware.chip else None
    spec = ExecutionSpec(
        name=JOB_NAME,
        project=PROJECT or None,
        group=GROUP or None,
        hardware=hardware,
        topology=topology,
        distributed=len(hardware.hosts) > 1,
    )

    # Get cluster and setup status directory
    cluster = hardware.hosts[0].cluster
    status_dir = _get_status_dir(cluster)

    # Generate unique run ID
    run_id = _generate_run_id()

    # Create run-specific directory structure: status/{project}/{group}/{name}/{run_id}/
    project = spec.project or "general"
    group = spec.group or "default"
    run_dir = status_dir / project / group / spec.name / run_id
    run_dir.mkdir(parents=True, exist_ok=True)

    # Setup logging with file output
    log_file = run_dir / "output.log"
    metadata_file = run_dir / "metadata.json"
    setup_logging(log_file=log_file)

    logger.info(f"BOOTSTRAP | run_id={run_id}, log={log_file}")

    # Write initial metadata
    _write_metadata(metadata_file, spec, cfg, run_id, status="running")
    logger.info(f"METADATA | written to {metadata_file}")

    job_key = cfg.job
    if job_key not in JOBS:
        _write_metadata(metadata_file, spec, cfg, run_id, status="failed")
        raise RuntimeError(
            f"Job '{job_key}' not in registry. Available: {list(JOBS.keys())}"
        )

    job_cls = JOBS[job_key]

    try:
        # Check for existing checkpoint if job is restorable (idempotent dispatch)
        if issubclass(job_cls, RestoreableJob):
            latest = RestoreableJob.latest(spec)
            if latest:
                logger.info(f"DISPATCH | restoring from checkpoint: {latest}")
                job, cfg = RestoreableJob.from_checkpoint(latest, spec)
                with configuration(cfg):
                    job()
                _write_metadata(metadata_file, spec, cfg, run_id, status="completed")
                return

        # No checkpoint found, start fresh
        logger.info(f"DISPATCH | starting new job: {job_key}")
        with configuration(cfg):
            job = job_cls(spec)
            job()

        _write_metadata(metadata_file, spec, cfg, run_id, status="completed")
        logger.info("BOOTSTRAP | job completed successfully")

    except Exception as e:
        logger.exception(f"BOOTSTRAP | job failed with exception: {e}")
        _write_metadata(metadata_file, spec, cfg, run_id, status="failed")
        raise


if __name__ == "__main__":
    main()
