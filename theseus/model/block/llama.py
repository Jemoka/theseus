from typing import Optional, List, Type, Any, Tuple

import jax

from theseus.config import configure
from theseus.model.module import Module
from theseus.model.layers import RMSNorm, LlamaMLP
from theseus.model.attention.grouped import GroupedSelfAttention


class LlamaDecoderBlock(Module):
    @classmethod
    def components(cls) -> List[Type[Any]]:
        return [RMSNorm, GroupedSelfAttention, LlamaMLP]

    @property
    def sharding(self) -> List[Tuple[str, Optional[Any]]]:
        return []

    def setup(self) -> None:
        self.rms_1 = configure(RMSNorm)
        self.attn = configure(GroupedSelfAttention)
        self.rms_2 = configure(RMSNorm)
        self.mlp = configure(LlamaMLP)

    def __call__(
        self,
        x: jax.Array,
        padding_mask: Optional[jax.Array] = None,
        deterministic: bool = False,
        positions: Optional[jax.Array] = None,
    ) -> jax.Array:
        h = self.rms_1(x)
        h = self.attn(
            h,
            padding_mask=padding_mask,
            deterministic=deterministic,
            sliding=False,
            positions=positions,
        )
        x = x + h

        h = self.rms_2(x)
        h = self.mlp(h, deterministic=deterministic)
        x = x + h
        return x
